{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import MDAnalysis as mda\n",
    "import MDAnalysisTests as mdtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class files():\n",
    "    def __init__(self):\n",
    "        return self\n",
    "\n",
    "    def read_file(pdb_file):\n",
    "        \"\"\"\n",
    "        files.readfile() reads a .pdb file using the readlines method. It also filters out all lines containing the keywords\n",
    "        REMARK, TER, TITLE, CRYST1, SCALE\n",
    "        and returns the list containing the lines (strings)\n",
    "        \"\"\"\n",
    "        lines = open(pdb_file, 'r').readlines()\n",
    "        lines = [k for k in lines if \"REMARK\" not in k]\n",
    "        lines = [k for k in lines if \"TER\" not in k]\n",
    "        lines = [k for k in lines if \"TITLE\" not in k]\n",
    "        lines = [k for k in lines if \"CRYST1\" not in k]\n",
    "        lines = [k for k in lines if \"SCALE\" not in k]\n",
    "        #lines = [k.replace(\"\\n\", '') for k in lines]\n",
    "        return lines\n",
    "\n",
    "    def write_file(file, lines):\n",
    "        \"\"\"\n",
    "        files.writefile takes a list of strings, e.g. from a read file like with the files.readfile function and opens a writer.\n",
    "        Using this write method, files.writefile writes the lines into a file that is saved, and closes the write-method.\n",
    "        It returns nothing.\n",
    "        \"\"\"\n",
    "        f = open(file, mode=\"w\", encoding=\"utf-8\")\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        return\n",
    "\n",
    "class line_operations():\n",
    "    \"\"\"\n",
    "    The class lines contains all the functions that operate on a line, which are iterated over in the operations functions.\n",
    "    It relies on being handed a single line or line_dict object as input.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return self\n",
    "\n",
    "    def read_pdb_line(line):\n",
    "        \"\"\"\n",
    "        line_operations.read_pdb_line() creates a dictionary (line_dict) which is filled with the content of the line it is given based on\n",
    "        string indexing. Based on the typical .pdb format, line_dict then knows:\n",
    "        atom, serial_no, atom_name, resname, chainID, resi_no, x_coord, y_coord, z_coord, occupancy,\n",
    "        temp_fac, segment, element_symbol.\n",
    "        line_operations.read_pdb_line() returns the dictionary line_dict.\n",
    "        \"\"\"\n",
    "        line_dict = {\n",
    "            \"atom\": line[0:6],\n",
    "            \"serial_no\": line[6:12],\n",
    "            \"atom_name\": line[12:16],\n",
    "            \"resname\": line[17:21],\n",
    "            \"chainID\": line[21],\n",
    "            \"resi_no\": line[22:27],\n",
    "            \"x_coord\": line[31:38],\n",
    "            \"y_coord\": line[39:46],\n",
    "            \"z_coord\": line[47:54],\n",
    "            \"occupancy\": line[55:60],\n",
    "            \"temp_fac\": line[60:66],\n",
    "            \"segment\": line[72:76],\n",
    "            \"element_symbol\": line[77:78],\n",
    "        }\n",
    "        \n",
    "        return line_dict\n",
    "\n",
    "    def create_line(line_dict):\n",
    "        \"\"\"\n",
    "        line_operations.create_line() takes a line_dict and creates the PDB-style line with the information contained in the dictionary.\n",
    "        It returns \"line\", an object containing the string that was produced.\n",
    "        \"\"\"\n",
    "        line = f'{line_dict[\"atom\"]}{line_dict[\"serial_no\"]}{line_dict[\"atom_name\"]} {line_dict[\"resname\"]}{line_dict[\"chainID\"]}{line_dict[\"resi_no\"]}    {line_dict[\"x_coord\"]} {line_dict[\"y_coord\"]} {line_dict[\"z_coord\"]} {line_dict[\"occupancy\"]}{line_dict[\"temp_fac\"]}      {line_dict[\"segment\"]} {line_dict[\"element_symbol\"]}  \\n'\n",
    "        return line\n",
    "\n",
    "    def fill_serial(serial_no: int, line_dict: dict):\n",
    "        \"\"\"\n",
    "        line_operations.fill_serial() takes a serial number (serial_no) and a line_dict and creates line_dict[\"serial_no\"] objects with\n",
    "        the appropriate number of spaces inserted in front, so that the serial number is inserted at the place the .pdb-format\n",
    "        dictates. It returns the line_dict with the appropriate serial_no.\n",
    "        \"\"\"\n",
    "        if serial_no >= 100000:\n",
    "            raise ValueError(\"Only serial numbers until 99.999 allowed. \")\n",
    "        line_dict[\"serial_no\"] = f\"{serial_no: >5}\"\n",
    "        return line_dict\n",
    "\n",
    "    def fill_resi_no(resi_no, line_dict):\n",
    "        \"\"\"\n",
    "        line_operations.fill_resi_no() takes a residue number (resi_no) and a line_dict and creates a line_dict with the serial\n",
    "        number and the appropriate number of spaces inserted into line_dict[\"resi_no\"]. It returns the line_dict.\n",
    "        \"\"\"\n",
    "        if resi_no >= 10000:\n",
    "            raise ValueError(\"Only residue numbers until 9.999 allowed. \")\n",
    "        line_dict[\"resi_no\"] = f\"{resi_no: >4}\"\n",
    "        return line_dict\n",
    "\n",
    "    def add_terminus(lines):\n",
    "        \"\"\"\n",
    "        line_operations.add_terminus() takes a list of strings (lines) and adds the string \"TER\" as the very last string in the list.\n",
    "        \"\"\"\n",
    "        if lines[-1] != \"TER\":\n",
    "            lines.append(\"TER\")\n",
    "        return lines\n",
    "\n",
    "    def exchange_segment(line_dict, segment):\n",
    "        \"\"\"\n",
    "        line_operations.exchange_segment() takes a line_dict and a segment name; then exchanges the previous segment name with the new\n",
    "        name and returns the line_dict with updated segment name. If the given segment name is too long, it will raise a\n",
    "        ValueError. If the given segment name is too short, it will start filling them up with whitespaces from the left\n",
    "        until the desired length of 4 characters is reached.\n",
    "        \"\"\"\n",
    "        if len(segment) > 4:\n",
    "            raise ValueError(\"segment value given is longer than 4. \")\n",
    "        if len(segment) < 4:\n",
    "            whitespaces=\" \"*(4-len(segment))\n",
    "            segment=f'{whitespaces}{segment}'\n",
    "        line_dict[\"segment\"] = segment\n",
    "        return line_dict\n",
    "\n",
    "    def exchange_chainID(line_dict, chainID):\n",
    "        \"\"\"\n",
    "        line_operations.exchange_chainID() takes a line_dict and a name for a chainID (maximum of 1 character) and exchanges the previous\n",
    "        chainID with the new chainID. It then returns the line_dict with the updated chainID.\n",
    "        \"\"\"\n",
    "        if len(chainID) > 1:\n",
    "            raise ValueError(\"chainID value given is longer than 1. \")\n",
    "        line_dict[\"chainID\"] = chainID\n",
    "        return line_dict\n",
    "\n",
    "class operations():\n",
    "    def __init__(self):\n",
    "        return self\n",
    "\n",
    "    def _filter_segment(lines, segname):\n",
    "        lines=[k for k in lines if segname in k]\n",
    "        return lines\n",
    "\n",
    "    def _split_segment(pdb_file, segname, pdb_id):\n",
    "        \"\"\"\n",
    "        operations.split_segment() takes a pdb_file, a segname, and a pdb_id; then reads the file and drops all instances that\n",
    "        do not have the segname within them. It writes the file as \"coords/{pdb_id}_{segname}.pdb. Not having a folder \"coords\"\n",
    "        will produce an error until the writefile function checks if the folder exists.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        lines=operations._filter_segment(lines=lines, segname=segname)\n",
    "        files.write_file(file=f'coords/{pdb_id}_{segname}.pdb', lines=lines)\n",
    "        return\n",
    "\n",
    "    def split_segments(pdb_file, segnames, pdb_id):\n",
    "        \"\"\"\n",
    "        operations.split_segments() takes a pdb_file and a list of segname strings (segnames) and a pdb_id; then for each\n",
    "        instance in segnames calls the operations.split_segment() function, producing a single file that contains only the\n",
    "        lines in the pdb that had the segname in them.\n",
    "        \"\"\"\n",
    "        for segname in segnames:\n",
    "            operations._split_segment(pdb_file=pdb_file, segname=segname, pdb_id=pdb_id)\n",
    "        return\n",
    "\n",
    "    def split_waterchains(pdb_file, output_name):\n",
    "        \"\"\"\n",
    "        operations.split_waterchains() takes a pdb_file and an output_name; first it reads the file (which should only contain\n",
    "        H2O molecules in the pdb format and TIP3 water model/other water model that has EXACTLY three atoms in the water) and\n",
    "        splits them into chains of 10.000 water molecules each. It writes the files based on the operations.renumber_tip3 method.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        length, counter, filenames=len(lines), 0, []\n",
    "        while counter < length:\n",
    "            lines_=lines[0:29997]\n",
    "            filename=\"coords/\"+output_name+f\"{counter//29997}.pdb\"\n",
    "            filenames.append(filename)\n",
    "            files.write_file(file=filename, lines=lines_)\n",
    "            lines=lines[29997:]\n",
    "            counter +=29997\n",
    "        for filename in filenames:\n",
    "            operations.renumber_tip3(pdb_file=filename, pdb_file_output=filename, segment=filename[12:16])\n",
    "        return\n",
    "\n",
    "    def fuse_segments(pdb_files, pdb_output):\n",
    "        \"\"\"\n",
    "        operations.fuse_segments() takes a list of strings that point to .pdb files and a name for a pdb_output; then it\n",
    "        appends all the files into one, removing potential \"TER\" lines, and writes a single fused file.\n",
    "        \"\"\"\n",
    "        lines_=[]\n",
    "        for pdb_file in pdb_files:\n",
    "            lines=files.read_file(pdb_file=pdb_file)\n",
    "            lines_.append(lines)\n",
    "            lines=[]\n",
    "        lines_ = list(itertools.chain(*lines_))\n",
    "        files.write_file(file=pdb_output, lines=lines_)\n",
    "        return\n",
    "\n",
    "    def add_segment(pdb_file, pdb_file_output, segment):\n",
    "        \"\"\"\n",
    "        operations.add_segment() takes a pdb_file, the name of a pdb_file_output, and a segment name (segment); then it\n",
    "        calls the line_operations.exchange_segment() function to exchange the segment identifier in the line_dict. In the end it\n",
    "        writes the file based on pdb_file_output.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        lines_ = []\n",
    "        serial_no=1\n",
    "        for line in lines:\n",
    "            line_dict=line_operations.read_pdb_line(line=line)\n",
    "            line_dict=line_operations.exchange_segment(line_dict=line_dict, segment=segment)\n",
    "            line_=line_operations.create_line(line_dict=line_dict)\n",
    "            lines_.append(line_)\n",
    "            serial_no+=1\n",
    "        files.write_file(file=pdb_file_output, lines=lines_)\n",
    "        return\n",
    "\n",
    "    def add_chainID(pdb_file, pdb_file_output, chainID):\n",
    "        \"\"\"\n",
    "        operations.add_chainID() takes a pdb_file and a output name pdb_file_output and a segment name; then iterates over\n",
    "        all lines in the PDB file changing the chainID. In the end it saves the new file according to pdb_file_output.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        lines_ = []\n",
    "        for line in lines:\n",
    "            line_dict=line_operations.read_pdb_line(line=line)\n",
    "            line_dict=line_operations.exchange_chainID(line_dict=line_dict, chainID=chainID)\n",
    "            line_=line_operations.create_line(line_dict=line_dict)\n",
    "            lines_.append(line_)\n",
    "        files.write_file(file=pdb_file_output, lines=lines_)\n",
    "        return\n",
    "\n",
    "    def change_temp_factors(pdb_file, restraints_file):\n",
    "        \"\"\"\n",
    "        operations.change_temp_factors() takes a pdb_file and a name for a restraints_file; then it\n",
    "        creates a restraints file based on the specifications of CHARMM-GUIs NAMD constraint files.\n",
    "        H-atoms will recieve the temp_fac 0.00\n",
    "        All C-atoms but CA (C-alphas) will recieve temp_fac 0.50\n",
    "        All other atoms will recieve temp_fac 1.00.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        lines_ = []\n",
    "        for line in lines:\n",
    "            line_dict=line_operations.read_pdb_line(line)\n",
    "            if line_dict[\"atom_name\"].startswith(\"H\"):\n",
    "                line_dict[\"temp_fac\"] = \"  0.00\"\n",
    "            else:\n",
    "                if line_dict[\"atom_name\"].startswith(\"C\") and not line_dict[\"atom_name\"].startswith(\"CA\"):\n",
    "                    line_dict[\"temp_fac\"] = \"  0.50\"\n",
    "                else:\n",
    "                    line_dict[\"temp_fac\"] = \"  1.00\"\n",
    "            line_ = line_operations.create_line(line_dict=line_dict)\n",
    "            lines_.append(line_)\n",
    "            if line.startswith(\"TER\"):\n",
    "                line_ = line\n",
    "                lines_.append(\"line_\")\n",
    "        files.write_file(file=restraints_file, lines=lines_)\n",
    "        lines=lines_\n",
    "        return\n",
    "\n",
    "    def renumber(pdb_file, pdb_file_output):\n",
    "        \"\"\"\n",
    "        operations.renumber() takes a pdb_file and a pdb_file_output name; then it checks if there are more than 99.999 atoms. If\n",
    "        so it will raise a ValueError, if not it will use the line_operations.fill_serial() method to renumber the atoms starting at 1. In\n",
    "        the end it will write a file based on pdb_file_output.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        if len(lines) > 99999:\n",
    "            raise ValueError(\"len(lines)>99999. Try again with less atoms.\")\n",
    "        lines_ = []\n",
    "        serial_no=1\n",
    "        for line in lines:\n",
    "            line_dict=line_operations.read_pdb_line(line=line)\n",
    "            line_dict=line_operations.fill_serial(serial_no=serial_no, line_dict=line_dict)\n",
    "            line_=line_operations.create_line(line_dict=line_dict)\n",
    "            lines_.append(line_)\n",
    "            serial_no+=1\n",
    "        files.write_file(file=pdb_file_output, lines=lines)\n",
    "        return\n",
    "\n",
    "    def renumber_tip3(pdb_file, pdb_file_output, segment):\n",
    "        \"\"\"\n",
    "        operations.renumber_tip3() takes a pdb_file, a pdb_file_output and a segment name; then it will read the file and\n",
    "        check if there are more than 99.999 atoms in the current file. If so it will raise a ValueError, if not it will\n",
    "        not only renumber the serial numbers of all atoms but also the residue numbers. This only works with a water model\n",
    "        that has exactly three atoms per water molecule. In the end it writes a file based on the pdb_file_output specifications.\n",
    "        \"\"\"\n",
    "        lines=files.read_file(pdb_file=pdb_file)\n",
    "        if len(lines) > 99999:\n",
    "            raise ValueError(\"len(lines)>99999. Try again with less atoms.\")\n",
    "        lines_ = []\n",
    "        serial_no=1\n",
    "        for line in lines:\n",
    "            line_dict=line_operations.read_pdb_line(line=line)\n",
    "            line_dict=line_operations.fill_serial(serial_no=serial_no, line_dict=line_dict)\n",
    "            resi_no=((serial_no-1)//3)+1\n",
    "            line_operations.fill_resi_no(resi_no=resi_no, line_dict=line_dict)\n",
    "            line_dict[\"segment\"] = segment\n",
    "            line_=line_operations.create_line(line_dict=line_dict)\n",
    "            lines_.append(line_)\n",
    "            serial_no+=1\n",
    "        files.write_file(file=pdb_file_output, lines=lines_)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id=\"3HB3\"\n",
    "operations.split_segments(pdb_file=\"coords/step5_aligned.pdb\", segnames=[\"MEMB\", \"TIP3\", \"IONS\"], pdb_id=pdb_id)\n",
    "operations.split_segments(pdb_file=\"coords/eoxox_aligned.pdb\", segnames=[\"ACHA\", \"BCHA\", \"META\", \"EHEM\", \"FEOH\", \"GHEM\"], pdb_id=pdb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_ACHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_ACHA.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_BCHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_BCHA.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_META.pdb\", pdb_file_output=f\"coords/{pdb_id}_META.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_EHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_EHEM.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_FEOH.pdb\", pdb_file_output=f\"coords/{pdb_id}_FEOH.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_GHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_GHEM.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_MEMB.pdb\", pdb_file_output=f\"coords/{pdb_id}_MEMB.pdb\")\n",
    "operations.renumber(pdb_file=f\"coords/{pdb_id}_IONS.pdb\", pdb_file_output=f\"coords/{pdb_id}_IONS.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      2  HN  GLY A  17     -28.850   5.427 -20.075  1.00  0.00      ACHA  \n",
    "ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      2  HN  GLY A  17     -28.850   5.427 -20.075  1.00  0.00      ACHA  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations.split_waterchains(pdb_file=f\"coords/{pdb_id}_TIP3.pdb\", output_name=pdb_id+\"_WAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATOM      1 OH2 TIP3X   1    -35.813 -37.759  26.812  1.00  0.00      WAT0    \n",
    "ATOM      2 H1  TIP3X   1    -35.786 -36.786  26.717  1.00  0.00      WAT0    \n",
    "ATOM  39827  OH2 TIP3X   1     -35.813 -37.759  26.812  1.00  0.00      TIP3  \n",
    "ATOM  39828  H1  TIP3X   1     -35.786 -36.786  26.717  1.00  0.00      TIP3  \n",
    "ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      2  HN  GLY A  17     -28.850   5.427 -20.075  1.00  0.00      ACHA  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_WAT0.pdb\", pdb_file_output=f\"coords/{pdb_id}_WAT0_.pdb\", chainID=\"W\")\n",
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_WAT1.pdb\", pdb_file_output=f\"coords/{pdb_id}_WAT1_.pdb\", chainID=\"W\")\n",
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_WAT2.pdb\", pdb_file_output=f\"coords/{pdb_id}_WAT2_.pdb\", chainID=\"W\")\n",
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_MEMB.pdb\", pdb_file_output=f\"coords/{pdb_id}_MEMB_.pdb\", chainID=\"M\")\n",
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_IONS.pdb\", pdb_file_output=f\"coords/{pdb_id}_IONS_.pdb\", chainID=\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATOM      1  OH2 TIP3X   1     -35.813 -37.759  26.812  1.00  0.00      WAT0    \n",
    "ATOM      2  H1  TIP3X   1     -35.786 -36.786  26.717  1.00  0.00      WAT0    \n",
    "ATOM      1   OH2 TIP3W   1      -35.813 -37.759  26.812  1.00  0.00      WAT0    \n",
    "ATOM      2   H1  TIP3W   1      -35.786 -36.786  26.717  1.00  0.00      WAT0    \n",
    "ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      2  HN  GLY A  17     -28.850   5.427 -20.075  1.00  0.00      ACHA  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations.add_chainID(pdb_file=f\"coords/{pdb_id}_ACHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_ACHA_.pdb\", chainID=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      1   N   GLY A  17      -28.775   4.437 -19.984  1.00101.81      ACHA  \n",
    "ATOM      2  HN  GLY A  17     -28.850   5.427 -20.075  1.00  0.00      ACHA  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATOM   1001  HN  THR A  81     -20.051  10.067  28.346  1.00  0.00      ACHA  \n",
      "ATOM   1001  HN  THR A  81     -20.051  10.067  28.346  1.00  0.00      ACHA    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ACHA = files.read_file(\"coords/3HB3_ACHA.pdb\")\n",
    "ACHA_line_pre = ACHA[1000]\n",
    "ACHA_dict = line_operations.read_pdb_line(ACHA_line_pre)\n",
    "ACHA_line_post = line_operations.create_line(ACHA_dict)\n",
    "print(ACHA_line_pre + ACHA_line_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ATOM      1  N   GLY A  17     -28.775   4.437 -19.984  1.00101.81      ACHA \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' HN '"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACHA_line_post[12:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9aff95240d2454192ab8549a0a0ea0879f0917f7124d16bef57df7e6dec046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
