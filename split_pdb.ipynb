{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import MDAnalysis as mda\n",
    "import MDAnalysisTests as mdtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class helpers():\n",
    "    class files():\n",
    "        def read_file(pdb_file):\n",
    "            lines = open(pdb_file, 'r').readlines()\n",
    "            lines = [k for k in lines if \"REMARK\" not in k]\n",
    "            lines = [k for k in lines if \"TER\" not in k]\n",
    "            lines = [k for k in lines if \"TITLE\" not in k]\n",
    "            lines = [k for k in lines if \"CRYST1\" not in k]\n",
    "            lines = [k for k in lines if \"SCALE\" not in k]\n",
    "            lines = [k for k in lines if \"TER\" not in k]\n",
    "            #lines = [k.replace(\"\\n\", '') for k in lines]\n",
    "            return lines\n",
    "        \n",
    "        def write_file(file, lines):\n",
    "            f = open(file, mode=\"w\", encoding=\"utf-8\")\n",
    "            f.writelines(lines)\n",
    "            f.close()\n",
    "            return \n",
    "\n",
    "\n",
    "    class lines():\n",
    "        def read_pdb_line(line):\n",
    "            line_dict = {\n",
    "                \"atom\": line[0:6],\n",
    "                \"serial_no\": line[6:12],\n",
    "                \"atom_name\": line[12:16],\n",
    "                \"resname\": line[17:21],\n",
    "                \"chain_ID\": line[21],\n",
    "                \"resi_sequence_no\": line[22:27],\n",
    "                \"x_coord\": line[31:38],\n",
    "                \"y_coord\": line[39:46],\n",
    "                \"z_coord\": line[47:54],\n",
    "                \"occupancy\": line[55:60],\n",
    "                \"temp_fac\": line[60:66],\n",
    "                \"segment\": line[72:76],\n",
    "                \"element_symbol\": line[77:78],\n",
    "            }\n",
    "            return line_dict\n",
    "\n",
    "        def create_line(line_dict):\n",
    "            line = f'{line_dict[\"atom\"]}{line_dict[\"serial_no\"]} {line_dict[\"atom_name\"]} {line_dict[\"resname\"]}{line_dict[\"chain_ID\"]}{line_dict[\"resi_sequence_no\"]}    {line_dict[\"x_coord\"]} {line_dict[\"y_coord\"]} {line_dict[\"z_coord\"]} {line_dict[\"occupancy\"]}{line_dict[\"temp_fac\"]}      {line_dict[\"segment\"]} {line_dict[\"element_symbol\"]}  \\n'\n",
    "            return line\n",
    "\n",
    "        def fill_serial(serial_no, line_dict):\n",
    "            if serial_no < 10:\n",
    "                line_dict[\"serial_no\"] = f\"    {serial_no}\"\n",
    "            if serial_no < 100 and serial_no >= 10:\n",
    "                line_dict[\"serial_no\"] = f\"   {serial_no}\"\n",
    "            if serial_no < 1000 and serial_no >= 100:\n",
    "                line_dict[\"serial_no\"] = f\"  {serial_no}\"\n",
    "            if serial_no < 10000 and serial_no >= 1000:\n",
    "                line_dict[\"serial_no\"] = f\" {serial_no}\"\n",
    "            if serial_no >= 10000:\n",
    "                line_dict[\"serial_no\"] = f\"{serial_no}\"\n",
    "            return line_dict\n",
    "        \n",
    "        def fill_resi_sequence_no(resi_no, line_dict):\n",
    "            if resi_no < 10:\n",
    "                line_dict[\"resi_sequence_no\"] = f\"   {resi_no} \"\n",
    "            if resi_no < 100 and resi_no >= 10:\n",
    "                line_dict[\"resi_sequence_no\"] = f\"  {resi_no} \"\n",
    "            if resi_no < 1000 and resi_no >= 100:\n",
    "                line_dict[\"resi_sequence_no\"] = f\" {resi_no} \"\n",
    "            if resi_no <= 9999 and resi_no >=1000:\n",
    "                line_dict[\"resi_sequence_no\"] = f\"{resi_no} \"\n",
    "            return line_dict\n",
    "        \n",
    "        def add_terminus(lines):\n",
    "            if lines[-1] != \"TER\":\n",
    "                lines.append(\"TER\")\n",
    "            return lines\n",
    "\n",
    "        def exchange_segment(line_dict, segment):\n",
    "            line_dict[\"segment\"] = segment\n",
    "            return line_dict\n",
    "\n",
    "        def exchange_chainID(line_dict, chainID):\n",
    "            line_dict[\"chainID\"] = chainID\n",
    "            return line_dict\n",
    "\n",
    "\n",
    "    class operations():\n",
    "        def split_segment(pdb_file, segname, pdb_id):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            lines=[k for k in lines if segname in k]\n",
    "            #lines=helpers.lines.add_terminus(lines)\n",
    "            helpers.files.write_file(file=f'coords/{pdb_id}_{segname}.pdb', lines=lines)\n",
    "            return\n",
    "        \n",
    "        def split_segments(pdb_file, segnames, pdb_id):\n",
    "            for segname in segnames:\n",
    "                helpers.operations.split_segment(pdb_file=pdb_file, segname=segname, pdb_id=pdb_id)\n",
    "            return\n",
    "\n",
    "        def split_waterchains(pdb_file, output_name):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            length, counter, filenames=len(lines), 0, []\n",
    "            while counter < length:\n",
    "                lines_=lines[0:29997]\n",
    "                lines_=helpers.lines.add_terminus(lines=lines_)\n",
    "                filename=\"coords/\"+output_name+f\"{counter//29997}.pdb\"\n",
    "                filenames.append(filename)\n",
    "                helpers.files.write_file(file=filename, lines=lines_)\n",
    "                lines=lines[29997:]\n",
    "                counter +=29997\n",
    "            for filename in filenames:\n",
    "                helpers.operations.renumber_tip3(pdb_file=filename, pdb_file_output=filename, segment=filename[12:16])\n",
    "            return\n",
    "\n",
    "        def fuse_segments(pdb_files, pdb_output):\n",
    "            lines_=[]\n",
    "            for pdb_file in pdb_files:\n",
    "                lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "                lines_.append(lines)\n",
    "                lines=[]\n",
    "            lines_ = list(itertools.chain(*lines_))\n",
    "            helpers.files.write_file(file=pdb_output, lines=lines_)\n",
    "            return\n",
    "\n",
    "        def add_segment(pdb_file, pdb_file_output, segment):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            lines_ = []\n",
    "            for line in lines:\n",
    "                line_dict=helpers.lines.read_pdb_line(line=line)\n",
    "                line_dict=helpers.lines.exchange_segment(line_dict=line_dict, segment=segment)\n",
    "                line_=helpers.lines.create_line(line_dict=line_dict)\n",
    "                lines_.append(line_)\n",
    "            lines=helpers.lines.add_terminus(lines=lines_)\n",
    "            helpers.files.write_file(file=pdb_file_output, lines=lines)\n",
    "            return \n",
    "\n",
    "        def add_chainID(pdb_file, pdb_file_output, chainID):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            lines_=[]\n",
    "            for line in lines:\n",
    "                line_dict=helpers.lines.read_pdb_line(line=line)\n",
    "                line_dict=helpers.lines.exchange_chainID(line_dict=line_dict, chainID = chainID)\n",
    "                line_=helpers.lines.create_line(line_dict=line_dict)\n",
    "                lines_.append(line_)\n",
    "            lines=helpers.lines.add_terminus(lines=lines_)\n",
    "            helpers.files.write_file(file=pdb_file_output, lines=lines)\n",
    "            return\n",
    "\n",
    "        def change_temp_factors(pdb_file, restraints_file):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            lines_ = []\n",
    "            for line in lines:\n",
    "                line_dict=helpers.lines.read_pdb_line(line)\n",
    "                if line_dict[\"atom_name\"].startswith(\"H\"):\n",
    "                    line_dict[\"temp_fac\"] = \"  0.00\"\n",
    "                else: \n",
    "                    if line_dict[\"atom_name\"].startswith(\"C\") and not line_dict[\"atom_name\"].startswith(\"CA\"):\n",
    "                        line_dict[\"temp_fac\"] = \"  0.50\"\n",
    "                    else:\n",
    "                        line_dict[\"temp_fac\"] = \"  1.00\"\n",
    "                line_ = helpers.lines.create_line(line_dict=line_dict)\n",
    "                lines_.append(line_)\n",
    "                if line.startswith(\"TER\"):\n",
    "                    line_ = line\n",
    "                    lines_.append(\"line_\")\n",
    "            helpers.files.write_file(file=restraints_file, lines=lines_)\n",
    "            lines=lines_\n",
    "            return\n",
    "        \n",
    "        def renumber(pdb_file, pdb_file_output):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            if len(lines) > 99999:\n",
    "                raise ValueError(\"len(lines)>99999. Try again with less atoms.\")\n",
    "            lines_ = []\n",
    "            serial_no=1\n",
    "            for line in lines:\n",
    "                line_dict=helpers.lines.read_pdb_line(line=line)\n",
    "                line_dict=helpers.lines.fill_serial(serial_no=serial_no, line_dict=line_dict)\n",
    "                line_=helpers.lines.create_line(line_dict=line_dict)\n",
    "                lines_.append(line_)\n",
    "                serial_no+=1\n",
    "            lines=helpers.lines.add_terminus(lines=lines_)\n",
    "            helpers.files.write_file(file=pdb_file_output, lines=lines)\n",
    "            return\n",
    "\n",
    "        def renumber_tip3(pdb_file, pdb_file_output, segment):\n",
    "            lines=helpers.files.read_file(pdb_file=pdb_file)\n",
    "            if len(lines) > 99999:\n",
    "                raise ValueError(\"len(lines)>99999. Try again with less atoms.\")\n",
    "            lines_ = []\n",
    "            serial_no=1\n",
    "            for line in lines:\n",
    "                line_dict=helpers.lines.read_pdb_line(line=line)\n",
    "                line_dict=helpers.lines.fill_serial(serial_no=serial_no, line_dict=line_dict)\n",
    "                resi_no=((serial_no-1)//3)+1\n",
    "                helpers.lines.fill_resi_sequence_no(resi_no=resi_no, line_dict=line_dict)\n",
    "                line_dict[\"segment\"] = segment\n",
    "                line_=helpers.lines.create_line(line_dict=line_dict)\n",
    "                lines_.append(line_)\n",
    "                serial_no+=1\n",
    "            lines=helpers.lines.add_terminus(lines=lines_)\n",
    "            helpers.files.write_file(file=pdb_file_output, lines=lines)\n",
    "            return \n",
    "\n",
    "\n",
    "    def __main__(pdb_file, pdb_id):#, add_segments):\n",
    "        #IF PDB FILE CAME WITHOUT SEGMENT IDENTIFIERS, USE:\n",
    "        #if add_segments==True:\n",
    "            #helpers.operations.split_segments(pdb_file=pdb_file, segnames=[\"ACHA\", \"BCHA\", \"META\", \"EHEM\", \"FEOH\", \"GHEM\", \"MEMB\", \"TIP3\", \"IONS\"], pdb_id=pdb_id)   \n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_ACHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_ACHA.pdb\", segment=\"ACHA\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_BCHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_BCHA.pdb\", segment=\"BCHA\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_CCHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_CCHA.pdb\", segment=\"CCHA\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_META.pdb\", pdb_file_output=f\"coords/{pdb_id}_META.pdb\", segment=\"META\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_EHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_EHEM.pdb\", segment=\"EHEM\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_FEOH.pdb\", pdb_file_output=f\"coords/{pdb_id}_FEOH.pdb\", segment=\"FEOH\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_GHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_GHEM.pdb\", segment=\"GHEM\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_MEMB.pdb\", pdb_file_output=f\"coords/{pdb_id}_MEMB.pdb\", segment=\"MEMB\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_TIP3.pdb\", pdb_file_output=f\"coords/{pdb_id}_TIP3.pdb\", segment=\"TIP3\")\n",
    "            #helpers.operations.add_segment(pdb_file=f\"coords/{pdb_id}_IONS.pdb\", pdb_file_output=f\"coords/{pdb_id}_IONS.pdb\", segment=\"IONS\")\n",
    "            #pdb_files = [f\"coords/{pdb_id}_ACHA.pdb\", f\"coords/{pdb_id}_BCHA.pdb\", f\"coords/{pdb_id}_CCHA.pdb\", f\"coords/{pdb_id}_META.pdb\", f\"coords/{pdb_id}_EHEM.pdb\", f\"coords/{pdb_id}_FEOH.pdb\", f\"coords/{pdb_id}_GHEM.pdb\", f\"coords/{pdb_id}_MEMB.pdb\", f\"coords/{pdb_id}_TIP3.pdb\", f\"coords/{pdb_id}_IONS.pdb\"]\n",
    "            #helpers.operations.fuse_segments(pdb_files=pdb_files, pdb_output=f\"coords/{pdb_id}_.pdb\")\n",
    "            #pdb_file=f\"coords/{pdb_id}_.pdb\"\n",
    "        \n",
    "        #SPLIT PDB FILE BASED ON CHAINS THAT WE WANT \n",
    "        #OMITTING SEGMENT NAMES IN THE segnames LIST WILL REMOVE THEM FROM FURTHER PROCESSING\n",
    "        helpers.operations.split_segments(pdb_file=pdb_file, segnames=[\"ACHA\", \"BCHA\", \"CCHA\", \"META\", \"EHEM\", \"FEOH\", \"GHEM\", \"OHMI\", \"MEMB\", \"TIP3\", \"IONS\"], pdb_id=pdb_id)\n",
    "\n",
    "        #FIX NUMBERING OF ATOM NUMBERS IF YOU SWITCHED RESIDUE SEQUENCE FROM PDB RES-SEQUENCE TO E.G. RTF-FILE SEQUENCE OF ATOMS\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_ACHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_ACHA.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_BCHA.pdb\", pdb_file_output=f\"coords/{pdb_id}_BCHA.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_META.pdb\", pdb_file_output=f\"coords/{pdb_id}_META.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_EHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_EHEM.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_FEOH.pdb\", pdb_file_output=f\"coords/{pdb_id}_FEOH.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_GHEM.pdb\", pdb_file_output=f\"coords/{pdb_id}_GHEM.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_OHMI.pdb\", pdb_file_output=f\"coords/{pdb_id}_OHMI.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_MEMB.pdb\", pdb_file_output=f\"coords/{pdb_id}_MEMB.pdb\")\n",
    "        helpers.operations.renumber(pdb_file=f\"coords/{pdb_id}_IONS.pdb\", pdb_file_output=f\"coords/{pdb_id}_IONS.pdb\")\n",
    "        \n",
    "        #FOR LARGE SYSTEMS: SPLIT WATER INTO MULTIPLE CHAINS OF 9999 RESIDUES EACH\n",
    "        #WATER RENUMBERING HAPPENS INSIDE THE SPLIT WATERCHAINS FUNCTION TO AVOID REDUNDANT USE OF FUNCTIONS\n",
    "        helpers.operations.split_waterchains(pdb_file=f\"coords/{pdb_id}_TIP3.pdb\", output_name=pdb_id+\"_WAT\")\n",
    "\n",
    "        #REMOVE TRASH\n",
    "        #os.remove(f\"coords/{pdb_id}_.pdb\")\n",
    "        #os.remove(f\"coords/{pdb_id}_TIP3.pdb\")\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.__main__(pdb_file=\"coords/Pmoxox/step5_aligned_Pmoxox.pdb\", pdb_id=\"3HB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.__main__(pdb_file=\"coords/Pmredox/step5_aligned_Pmredox.pdb\", pdb_id=\"3HB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.__main__(pdb_file=\"coords/Proxred/step5_aligned_Proxred.pdb\", pdb_id=\"3HB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.__main__(pdb_file=\"coords/Foxox/step5_aligned_Foxox.pdb\", pdb_id=\"3HB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9aff95240d2454192ab8549a0a0ea0879f0917f7124d16bef57df7e6dec046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
